"""
TradingAgents-CN v1.0.0-preview FastAPI Backend
ä¸»åº”ç”¨ç¨‹åºå…¥å£

Copyright (c) 2025 hsliuping. All rights reserved.
ç‰ˆæƒæ‰€æœ‰ (c) 2025 hsliupingã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

This software is proprietary and confidential. Unauthorized copying, distribution,
or use of this software, via any medium, is strictly prohibited.
æœ¬è½¯ä»¶ä¸ºä¸“æœ‰å’Œæœºå¯†è½¯ä»¶ã€‚ä¸¥ç¦é€šè¿‡ä»»ä½•åª’ä»‹æœªç»æˆæƒå¤åˆ¶ã€åˆ†å‘æˆ–ä½¿ç”¨æœ¬è½¯ä»¶ã€‚

For commercial licensing, please contact: hsliup@163.com
å•†ä¸šè®¸å¯å’¨è¯¢ï¼Œè¯·è”ç³»ï¼šhsliup@163.com
"""

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import logging
import time
from contextlib import asynccontextmanager
import asyncio

from app.core.config import settings
from app.core.database import init_db, close_db
from app.core.logging_config import setup_logging
from app.routers import auth, analysis, screening, queue, sse, health, favorites, config, reports, database, operation_logs, tags, tushare_init, akshare_init, baostock_init, historical_data, multi_period_sync, financial_data, news_data, social_media, internal_messages, usage_statistics, model_capabilities
from app.routers import sync as sync_router, multi_source_sync
from app.routers import stocks as stocks_router
from app.routers import stock_data as stock_data_router
from app.routers import notifications as notifications_router
from app.routers import scheduler as scheduler_router
from app.services.basics_sync_service import get_basics_sync_service
from app.services.scheduler_service import set_scheduler_instance
from app.worker.tushare_sync_service import (
    run_tushare_basic_info_sync,
    run_tushare_quotes_sync,
    run_tushare_historical_sync,
    run_tushare_financial_sync,
    run_tushare_status_check
)
from app.worker.akshare_sync_service import (
    run_akshare_basic_info_sync,
    run_akshare_quotes_sync,
    run_akshare_historical_sync,
    run_akshare_financial_sync,
    run_akshare_status_check
)
from app.worker.baostock_sync_service import (
    run_baostock_basic_info_sync,
    run_baostock_quotes_sync,
    run_baostock_historical_sync,
    run_baostock_status_check
)
from app.middleware.operation_log_middleware import OperationLogMiddleware
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from app.services.quotes_ingestion_service import QuotesIngestionService
from app.routers import paper as paper_router


async def _print_config_summary(logger):
    """æ˜¾ç¤ºé…ç½®æ‘˜è¦"""
    try:
        logger.info("=" * 70)
        logger.info("ğŸ“‹ TradingAgents-CN Configuration Summary")
        logger.info("=" * 70)

        # ç¯å¢ƒä¿¡æ¯
        env = "Production" if settings.is_production else "Development"
        logger.info(f"Environment: {env}")

        # æ•°æ®åº“è¿æ¥
        logger.info(f"MongoDB: {settings.MONGODB_HOST}:{settings.MONGODB_PORT}/{settings.MONGODB_DATABASE}")
        logger.info(f"Redis: {settings.REDIS_HOST}:{settings.REDIS_PORT}/{settings.REDIS_DB}")

        # æ£€æŸ¥å¤§æ¨¡å‹é…ç½®
        try:
            from app.services.config_service import config_service
            config = await config_service.get_system_config()
            if config and config.llm_configs:
                enabled_llms = [llm for llm in config.llm_configs if llm.enabled]
                logger.info(f"Enabled LLMs: {len(enabled_llms)}")
                if enabled_llms:
                    for llm in enabled_llms[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                        logger.info(f"  â€¢ {llm.provider.value}: {llm.model_name}")
                    if len(enabled_llms) > 3:
                        logger.info(f"  â€¢ ... and {len(enabled_llms) - 3} more")
                else:
                    logger.warning("âš ï¸  No LLM enabled. Please configure at least one LLM in Web UI.")
            else:
                logger.warning("âš ï¸  No LLM configured. Please configure at least one LLM in Web UI.")
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to check LLM configs: {e}")

        # æ£€æŸ¥æ•°æ®æºé…ç½®
        try:
            if config and config.data_source_configs:
                enabled_sources = [ds for ds in config.data_source_configs if ds.enabled]
                logger.info(f"Enabled Data Sources: {len(enabled_sources)}")
                if enabled_sources:
                    for ds in enabled_sources[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                        logger.info(f"  â€¢ {ds.type.value}: {ds.name}")
                    if len(enabled_sources) > 3:
                        logger.info(f"  â€¢ ... and {len(enabled_sources) - 3} more")
            else:
                logger.info("Data Sources: Using default (AKShare)")
        except Exception as e:
            logger.warning(f"âš ï¸  Failed to check data source configs: {e}")

        logger.info("=" * 70)
    except Exception as e:
        logger.error(f"Failed to print config summary: {e}")


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    setup_logging()
    logger = logging.getLogger("app.main")

    # éªŒè¯å¯åŠ¨é…ç½®
    try:
        from app.core.startup_validator import validate_startup_config
        validate_startup_config()
    except Exception as e:
        logger.error(f"é…ç½®éªŒè¯å¤±è´¥: {e}")
        raise

    await init_db()

    # ğŸ”§ é…ç½®æ¡¥æ¥ï¼šå°†ç»Ÿä¸€é…ç½®å†™å…¥ç¯å¢ƒå˜é‡ï¼Œä¾› TradingAgents æ ¸å¿ƒåº“ä½¿ç”¨
    try:
        from app.core.config_bridge import bridge_config_to_env
        bridge_config_to_env()
    except Exception as e:
        logger.warning(f"âš ï¸  é…ç½®æ¡¥æ¥å¤±è´¥: {e}")
        logger.warning("âš ï¸  TradingAgents å°†ä½¿ç”¨ .env æ–‡ä»¶ä¸­çš„é…ç½®")

    # Apply dynamic settings (log_level, enable_monitoring) from ConfigProvider
    try:
        from app.services.config_provider import provider as config_provider  # local import to avoid early DB init issues
        eff = await config_provider.get_effective_system_settings()
        desired_level = str(eff.get("log_level", "INFO")).upper()
        setup_logging(log_level=desired_level)
        for name in ("webapi", "worker", "uvicorn", "fastapi"):
            logging.getLogger(name).setLevel(desired_level)
        try:
            from app.middleware.operation_log_middleware import set_operation_log_enabled
            set_operation_log_enabled(bool(eff.get("enable_monitoring", True)))
        except Exception:
            pass
    except Exception as e:
        logging.getLogger("webapi").warning(f"Failed to apply dynamic settings: {e}")

    # æ˜¾ç¤ºé…ç½®æ‘˜è¦
    await _print_config_summary(logger)

    logger.info("TradingAgents FastAPI backend started")

    # å¯åŠ¨æœŸï¼šè‹¥éœ€è¦åœ¨ä¼‘å¸‚æ—¶è¡¥å……ä¸Šä¸€äº¤æ˜“æ—¥æ”¶ç›˜å¿«ç…§
    if settings.QUOTES_BACKFILL_ON_STARTUP:
        try:
            qi = QuotesIngestionService()
            await qi.ensure_indexes()
            await qi.backfill_last_close_snapshot_if_needed()
        except Exception as e:
            logger.warning(f"Startup backfill failed (ignored): {e}")

    # å¯åŠ¨æ¯æ—¥å®šæ—¶ä»»åŠ¡ï¼šå¯é…ç½®
    scheduler: AsyncIOScheduler | None = None
    try:
        from croniter import croniter
    except Exception:
        croniter = None  # å¯é€‰ä¾èµ–
    try:
        scheduler = AsyncIOScheduler(timezone=settings.TIMEZONE)
        service = get_basics_sync_service()
        # ç«‹å³åœ¨å¯åŠ¨åå°è¯•ä¸€æ¬¡ï¼ˆä¸é˜»å¡ï¼‰
        asyncio.create_task(service.run_full_sync(force=False))

        # é…ç½®è°ƒåº¦ï¼šä¼˜å…ˆä½¿ç”¨ CRONï¼Œå…¶æ¬¡ä½¿ç”¨ HH:MM
        if settings.SYNC_STOCK_BASICS_ENABLED:
            if settings.SYNC_STOCK_BASICS_CRON:
                # å¦‚æœæä¾›äº†cronè¡¨è¾¾å¼
                scheduler.add_job(
                    service.run_full_sync,  # coroutine function; AsyncIOScheduler will await it
                    CronTrigger.from_crontab(settings.SYNC_STOCK_BASICS_CRON, timezone=settings.TIMEZONE),
                    id="basics_sync_service"
                )
                logger.info(f"ğŸ“… Stock basics sync scheduled by CRON: {settings.SYNC_STOCK_BASICS_CRON} ({settings.TIMEZONE})")
            else:
                hh, mm = (settings.SYNC_STOCK_BASICS_TIME or "06:30").split(":")
                scheduler.add_job(
                    service.run_full_sync,  # coroutine function; AsyncIOScheduler will await it
                    CronTrigger(hour=int(hh), minute=int(mm), timezone=settings.TIMEZONE),
                    id="basics_sync_service"
                )
                logger.info(f"ğŸ“… Stock basics sync scheduled daily at {settings.SYNC_STOCK_BASICS_TIME} ({settings.TIMEZONE})")

        # å®æ—¶è¡Œæƒ…å…¥åº“ä»»åŠ¡ï¼ˆæ¯Nç§’ï¼‰ï¼Œå†…éƒ¨è‡ªåˆ¤äº¤æ˜“æ—¶æ®µ
        if settings.QUOTES_INGEST_ENABLED:
            quotes_ingestion = QuotesIngestionService()
            await quotes_ingestion.ensure_indexes()
            scheduler.add_job(
                quotes_ingestion.run_once,  # coroutine function; AsyncIOScheduler will await it
                IntervalTrigger(seconds=settings.QUOTES_INGEST_INTERVAL_SECONDS, timezone=settings.TIMEZONE),
                id="quotes_ingestion_service"
            )
            logger.info(f"â± å®æ—¶è¡Œæƒ…å…¥åº“ä»»åŠ¡å·²å¯åŠ¨: æ¯ {settings.QUOTES_INGEST_INTERVAL_SECONDS}s")

        # Tushareç»Ÿä¸€æ•°æ®åŒæ­¥ä»»åŠ¡é…ç½®
        if settings.TUSHARE_UNIFIED_ENABLED:
            logger.info("ğŸ”„ é…ç½®Tushareç»Ÿä¸€æ•°æ®åŒæ­¥ä»»åŠ¡...")

            # åŸºç¡€ä¿¡æ¯åŒæ­¥ä»»åŠ¡
            if settings.TUSHARE_BASIC_INFO_SYNC_ENABLED:
                scheduler.add_job(
                    run_tushare_basic_info_sync,
                    CronTrigger.from_crontab(settings.TUSHARE_BASIC_INFO_SYNC_CRON, timezone=settings.TIMEZONE),
                    id="tushare_basic_info_sync",
                    kwargs={"force_update": False}
                )
                logger.info(f"ğŸ“… TushareåŸºç¡€ä¿¡æ¯åŒæ­¥å·²é…ç½®: {settings.TUSHARE_BASIC_INFO_SYNC_CRON}")

            # å®æ—¶è¡Œæƒ…åŒæ­¥ä»»åŠ¡
            if settings.TUSHARE_QUOTES_SYNC_ENABLED:
                scheduler.add_job(
                    run_tushare_quotes_sync,
                    CronTrigger.from_crontab(settings.TUSHARE_QUOTES_SYNC_CRON, timezone=settings.TIMEZONE),
                    id="tushare_quotes_sync"
                )
                logger.info(f"ğŸ“ˆ Tushareè¡Œæƒ…åŒæ­¥å·²é…ç½®: {settings.TUSHARE_QUOTES_SYNC_CRON}")

            # å†å²æ•°æ®åŒæ­¥ä»»åŠ¡
            if settings.TUSHARE_HISTORICAL_SYNC_ENABLED:
                scheduler.add_job(
                    run_tushare_historical_sync,
                    CronTrigger.from_crontab(settings.TUSHARE_HISTORICAL_SYNC_CRON, timezone=settings.TIMEZONE),
                    id="tushare_historical_sync",
                    kwargs={"incremental": True}
                )
                logger.info(f"ğŸ“Š Tushareå†å²æ•°æ®åŒæ­¥å·²é…ç½®: {settings.TUSHARE_HISTORICAL_SYNC_CRON}")

            # è´¢åŠ¡æ•°æ®åŒæ­¥ä»»åŠ¡
            if settings.TUSHARE_FINANCIAL_SYNC_ENABLED:
                scheduler.add_job(
                    run_tushare_financial_sync,
                    CronTrigger.from_crontab(settings.TUSHARE_FINANCIAL_SYNC_CRON, timezone=settings.TIMEZONE),
                    id="tushare_financial_sync"
                )
                logger.info(f"ğŸ’° Tushareè´¢åŠ¡æ•°æ®åŒæ­¥å·²é…ç½®: {settings.TUSHARE_FINANCIAL_SYNC_CRON}")

            # çŠ¶æ€æ£€æŸ¥ä»»åŠ¡
            if settings.TUSHARE_STATUS_CHECK_ENABLED:
                scheduler.add_job(
                    run_tushare_status_check,
                    CronTrigger.from_crontab(settings.TUSHARE_STATUS_CHECK_CRON, timezone=settings.TIMEZONE),
                    id="tushare_status_check"
                )
                logger.info(f"ğŸ” TushareçŠ¶æ€æ£€æŸ¥å·²é…ç½®: {settings.TUSHARE_STATUS_CHECK_CRON}")

        # AKShareç»Ÿä¸€æ•°æ®åŒæ­¥ä»»åŠ¡é…ç½®
        logger.info("ğŸ”„ é…ç½®AKShareç»Ÿä¸€æ•°æ®åŒæ­¥ä»»åŠ¡...")

        # åŸºç¡€ä¿¡æ¯åŒæ­¥ä»»åŠ¡
        scheduler.add_job(
            run_akshare_basic_info_sync,
            CronTrigger.from_crontab(settings.AKSHARE_BASIC_INFO_SYNC_CRON, timezone=settings.TIMEZONE),
            id="akshare_basic_info_sync",
            kwargs={"force_update": False}
        )
        if not (settings.AKSHARE_UNIFIED_ENABLED and settings.AKSHARE_BASIC_INFO_SYNC_ENABLED):
            scheduler.pause_job("akshare_basic_info_sync")
            logger.info(f"â¸ï¸ AKShareåŸºç¡€ä¿¡æ¯åŒæ­¥å·²æ·»åŠ ä½†æš‚åœ: {settings.AKSHARE_BASIC_INFO_SYNC_CRON}")
        else:
            logger.info(f"ğŸ“… AKShareåŸºç¡€ä¿¡æ¯åŒæ­¥å·²é…ç½®: {settings.AKSHARE_BASIC_INFO_SYNC_CRON}")

        # å®æ—¶è¡Œæƒ…åŒæ­¥ä»»åŠ¡
        scheduler.add_job(
            run_akshare_quotes_sync,
            CronTrigger.from_crontab(settings.AKSHARE_QUOTES_SYNC_CRON, timezone=settings.TIMEZONE),
            id="akshare_quotes_sync"
        )
        if not (settings.AKSHARE_UNIFIED_ENABLED and settings.AKSHARE_QUOTES_SYNC_ENABLED):
            scheduler.pause_job("akshare_quotes_sync")
            logger.info(f"â¸ï¸ AKShareè¡Œæƒ…åŒæ­¥å·²æ·»åŠ ä½†æš‚åœ: {settings.AKSHARE_QUOTES_SYNC_CRON}")
        else:
            logger.info(f"ğŸ“ˆ AKShareè¡Œæƒ…åŒæ­¥å·²é…ç½®: {settings.AKSHARE_QUOTES_SYNC_CRON}")

        # å†å²æ•°æ®åŒæ­¥ä»»åŠ¡
        scheduler.add_job(
            run_akshare_historical_sync,
            CronTrigger.from_crontab(settings.AKSHARE_HISTORICAL_SYNC_CRON, timezone=settings.TIMEZONE),
            id="akshare_historical_sync",
            kwargs={"incremental": True}
        )
        if not (settings.AKSHARE_UNIFIED_ENABLED and settings.AKSHARE_HISTORICAL_SYNC_ENABLED):
            scheduler.pause_job("akshare_historical_sync")
            logger.info(f"â¸ï¸ AKShareå†å²æ•°æ®åŒæ­¥å·²æ·»åŠ ä½†æš‚åœ: {settings.AKSHARE_HISTORICAL_SYNC_CRON}")
        else:
            logger.info(f"ğŸ“Š AKShareå†å²æ•°æ®åŒæ­¥å·²é…ç½®: {settings.AKSHARE_HISTORICAL_SYNC_CRON}")

        # è´¢åŠ¡æ•°æ®åŒæ­¥ä»»åŠ¡
        scheduler.add_job(
            run_akshare_financial_sync,
            CronTrigger.from_crontab(settings.AKSHARE_FINANCIAL_SYNC_CRON, timezone=settings.TIMEZONE),
            id="akshare_financial_sync"
        )
        if not (settings.AKSHARE_UNIFIED_ENABLED and settings.AKSHARE_FINANCIAL_SYNC_ENABLED):
            scheduler.pause_job("akshare_financial_sync")
            logger.info(f"â¸ï¸ AKShareè´¢åŠ¡æ•°æ®åŒæ­¥å·²æ·»åŠ ä½†æš‚åœ: {settings.AKSHARE_FINANCIAL_SYNC_CRON}")
        else:
            logger.info(f"ğŸ’° AKShareè´¢åŠ¡æ•°æ®åŒæ­¥å·²é…ç½®: {settings.AKSHARE_FINANCIAL_SYNC_CRON}")

        # çŠ¶æ€æ£€æŸ¥ä»»åŠ¡
        scheduler.add_job(
            run_akshare_status_check,
            CronTrigger.from_crontab(settings.AKSHARE_STATUS_CHECK_CRON, timezone=settings.TIMEZONE),
            id="akshare_status_check"
        )
        if not (settings.AKSHARE_UNIFIED_ENABLED and settings.AKSHARE_STATUS_CHECK_ENABLED):
            scheduler.pause_job("akshare_status_check")
            logger.info(f"â¸ï¸ AKShareçŠ¶æ€æ£€æŸ¥å·²æ·»åŠ ä½†æš‚åœ: {settings.AKSHARE_STATUS_CHECK_CRON}")
        else:
            logger.info(f"ğŸ” AKShareçŠ¶æ€æ£€æŸ¥å·²é…ç½®: {settings.AKSHARE_STATUS_CHECK_CRON}")

        # BaoStockç»Ÿä¸€æ•°æ®åŒæ­¥ä»»åŠ¡é…ç½®
        logger.info("ğŸ”„ é…ç½®BaoStockç»Ÿä¸€æ•°æ®åŒæ­¥ä»»åŠ¡...")

        # åŸºç¡€ä¿¡æ¯åŒæ­¥ä»»åŠ¡
        scheduler.add_job(
            run_baostock_basic_info_sync,
            CronTrigger.from_crontab(settings.BAOSTOCK_BASIC_INFO_SYNC_CRON, timezone=settings.TIMEZONE),
            id="baostock_basic_info_sync"
        )
        if not (settings.BAOSTOCK_UNIFIED_ENABLED and settings.BAOSTOCK_BASIC_INFO_SYNC_ENABLED):
            scheduler.pause_job("baostock_basic_info_sync")
            logger.info(f"â¸ï¸ BaoStockåŸºç¡€ä¿¡æ¯åŒæ­¥å·²æ·»åŠ ä½†æš‚åœ: {settings.BAOSTOCK_BASIC_INFO_SYNC_CRON}")
        else:
            logger.info(f"ğŸ“‹ BaoStockåŸºç¡€ä¿¡æ¯åŒæ­¥å·²é…ç½®: {settings.BAOSTOCK_BASIC_INFO_SYNC_CRON}")

        # è¡Œæƒ…åŒæ­¥ä»»åŠ¡
        scheduler.add_job(
            run_baostock_quotes_sync,
            CronTrigger.from_crontab(settings.BAOSTOCK_QUOTES_SYNC_CRON, timezone=settings.TIMEZONE),
            id="baostock_quotes_sync"
        )
        if not (settings.BAOSTOCK_UNIFIED_ENABLED and settings.BAOSTOCK_QUOTES_SYNC_ENABLED):
            scheduler.pause_job("baostock_quotes_sync")
            logger.info(f"â¸ï¸ BaoStockè¡Œæƒ…åŒæ­¥å·²æ·»åŠ ä½†æš‚åœ: {settings.BAOSTOCK_QUOTES_SYNC_CRON}")
        else:
            logger.info(f"ğŸ“ˆ BaoStockè¡Œæƒ…åŒæ­¥å·²é…ç½®: {settings.BAOSTOCK_QUOTES_SYNC_CRON}")

        # å†å²æ•°æ®åŒæ­¥ä»»åŠ¡
        scheduler.add_job(
            run_baostock_historical_sync,
            CronTrigger.from_crontab(settings.BAOSTOCK_HISTORICAL_SYNC_CRON, timezone=settings.TIMEZONE),
            id="baostock_historical_sync"
        )
        if not (settings.BAOSTOCK_UNIFIED_ENABLED and settings.BAOSTOCK_HISTORICAL_SYNC_ENABLED):
            scheduler.pause_job("baostock_historical_sync")
            logger.info(f"â¸ï¸ BaoStockå†å²æ•°æ®åŒæ­¥å·²æ·»åŠ ä½†æš‚åœ: {settings.BAOSTOCK_HISTORICAL_SYNC_CRON}")
        else:
            logger.info(f"ğŸ“Š BaoStockå†å²æ•°æ®åŒæ­¥å·²é…ç½®: {settings.BAOSTOCK_HISTORICAL_SYNC_CRON}")

        # çŠ¶æ€æ£€æŸ¥ä»»åŠ¡
        scheduler.add_job(
            run_baostock_status_check,
            CronTrigger.from_crontab(settings.BAOSTOCK_STATUS_CHECK_CRON, timezone=settings.TIMEZONE),
            id="baostock_status_check"
        )
        if not (settings.BAOSTOCK_UNIFIED_ENABLED and settings.BAOSTOCK_STATUS_CHECK_ENABLED):
            scheduler.pause_job("baostock_status_check")
            logger.info(f"â¸ï¸ BaoStockçŠ¶æ€æ£€æŸ¥å·²æ·»åŠ ä½†æš‚åœ: {settings.BAOSTOCK_STATUS_CHECK_CRON}")
        else:
            logger.info(f"ğŸ” BaoStockçŠ¶æ€æ£€æŸ¥å·²é…ç½®: {settings.BAOSTOCK_STATUS_CHECK_CRON}")

        # æ–°é—»æ•°æ®åŒæ­¥ä»»åŠ¡é…ç½®ï¼ˆä½¿ç”¨AKShareåŒæ­¥æ‰€æœ‰è‚¡ç¥¨æ–°é—»ï¼‰
        if settings.NEWS_SYNC_ENABLED:
            logger.info("ğŸ”„ é…ç½®æ–°é—»æ•°æ®åŒæ­¥ä»»åŠ¡...")

            from app.worker.akshare_sync_service import get_akshare_sync_service

            async def run_news_sync():
                """è¿è¡Œæ–°é—»åŒæ­¥ä»»åŠ¡ - ä½¿ç”¨AKShareåŒæ­¥æ‰€æœ‰è‚¡ç¥¨æ–°é—»"""
                try:
                    logger.info("ğŸ“° å¼€å§‹æ–°é—»æ•°æ®åŒæ­¥ï¼ˆAKShareï¼‰...")
                    service = await get_akshare_sync_service()
                    result = await service.sync_news_data(
                        symbols=None,  # Noneè¡¨ç¤ºåŒæ­¥æ‰€æœ‰è‚¡ç¥¨
                        max_news_per_stock=settings.NEWS_SYNC_MAX_PER_SOURCE
                    )
                    logger.info(
                        f"âœ… æ–°é—»åŒæ­¥å®Œæˆ: "
                        f"å¤„ç†{result['total_processed']}åªè‚¡ç¥¨, "
                        f"æˆåŠŸ{result['success_count']}åª, "
                        f"å¤±è´¥{result['error_count']}åª, "
                        f"æ–°é—»æ€»æ•°{result['news_count']}æ¡, "
                        f"è€—æ—¶{(datetime.utcnow() - result['start_time']).total_seconds():.2f}ç§’"
                    )
                except Exception as e:
                    logger.error(f"âŒ æ–°é—»åŒæ­¥å¤±è´¥: {e}", exc_info=True)

            scheduler.add_job(
                run_news_sync,
                CronTrigger.from_crontab(settings.NEWS_SYNC_CRON, timezone=settings.TIMEZONE),
                id="news_sync"
            )
            logger.info(f"ğŸ“° æ–°é—»æ•°æ®åŒæ­¥å·²é…ç½®: {settings.NEWS_SYNC_CRON}")

        scheduler.start()

        # è®¾ç½®è°ƒåº¦å™¨å®ä¾‹åˆ°æœåŠ¡ä¸­ï¼Œä»¥ä¾¿APIå¯ä»¥ç®¡ç†ä»»åŠ¡
        set_scheduler_instance(scheduler)
        logger.info("âœ… è°ƒåº¦å™¨æœåŠ¡å·²åˆå§‹åŒ–")
    except Exception as e:
        logger.warning(f"Failed to start scheduler: {e}")

    try:
        yield
    finally:
        # å…³é—­æ—¶æ¸…ç†
        if scheduler:
            try:
                scheduler.shutdown(wait=False)
                logger.info("ğŸ›‘ Scheduler stopped")
            except Exception as e:
                logger.warning(f"Scheduler shutdown error: {e}")
        await close_db()
        logger.info("TradingAgents FastAPI backend stopped")


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="TradingAgents-CN API",
    description="è‚¡ç¥¨åˆ†æä¸æ‰¹é‡é˜Ÿåˆ—ç³»ç»Ÿ API",
    version="0.1.16",
    docs_url="/docs" if settings.DEBUG else None,
    redoc_url="/redoc" if settings.DEBUG else None,
    lifespan=lifespan
)

# å®‰å…¨ä¸­é—´ä»¶
if not settings.DEBUG:
    app.add_middleware(
        TrustedHostMiddleware,
        allowed_hosts=settings.ALLOWED_HOSTS
    )

# CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)


# æ“ä½œæ—¥å¿—ä¸­é—´ä»¶
app.add_middleware(OperationLogMiddleware)


# è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()

    # è·³è¿‡å¥åº·æ£€æŸ¥å’Œé™æ€æ–‡ä»¶è¯·æ±‚çš„æ—¥å¿—
    if request.url.path in ["/health", "/favicon.ico"] or request.url.path.startswith("/static"):
        response = await call_next(request)
        return response

    # ä½¿ç”¨webapi loggerè®°å½•è¯·æ±‚
    logger = logging.getLogger("webapi")
    logger.info(f"ğŸ”„ {request.method} {request.url.path} - å¼€å§‹å¤„ç†")

    response = await call_next(request)
    process_time = time.time() - start_time

    # è®°å½•è¯·æ±‚å®Œæˆ
    status_emoji = "âœ…" if response.status_code < 400 else "âŒ"
    logger.info(f"{status_emoji} {request.method} {request.url.path} - çŠ¶æ€: {response.status_code} - è€—æ—¶: {process_time:.3f}s")

    return response


# å…¨å±€å¼‚å¸¸å¤„ç†
# è¯·æ±‚ID/Trace-ID ä¸­é—´ä»¶ï¼ˆéœ€ä½œä¸ºæœ€å¤–å±‚ï¼Œæ”¾åœ¨å‡½æ•°å¼ä¸­é—´ä»¶ä¹‹åï¼‰
from app.middleware.request_id import RequestIDMiddleware
app.add_middleware(RequestIDMiddleware)

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logging.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "error": {
                "code": "INTERNAL_SERVER_ERROR",
                "message": "Internal server error occurred",
                "request_id": getattr(request.state, "request_id", None)
            }
        }
    )


# æµ‹è¯•ç«¯ç‚¹ - éªŒè¯ä¸­é—´ä»¶æ˜¯å¦å·¥ä½œ
@app.get("/api/test-log")
async def test_log():
    """æµ‹è¯•æ—¥å¿—ä¸­é—´ä»¶æ˜¯å¦å·¥ä½œ"""
    print("ğŸ§ª æµ‹è¯•ç«¯ç‚¹è¢«è°ƒç”¨ - è¿™æ¡æ¶ˆæ¯åº”è¯¥å‡ºç°åœ¨æ§åˆ¶å°")
    return {"message": "æµ‹è¯•æˆåŠŸ", "timestamp": time.time()}

# æ³¨å†Œè·¯ç”±
app.include_router(health.router, prefix="/api", tags=["health"])
app.include_router(auth.router, prefix="/api/auth", tags=["authentication"])
app.include_router(analysis.router, prefix="/api/analysis", tags=["analysis"])
app.include_router(reports.router, tags=["reports"])
app.include_router(screening.router, prefix="/api/screening", tags=["screening"])
app.include_router(queue.router, prefix="/api/queue", tags=["queue"])
app.include_router(favorites.router, prefix="/api", tags=["favorites"])
app.include_router(stocks_router.router, prefix="/api", tags=["stocks"])
app.include_router(stock_data_router.router, tags=["stock-data"])
app.include_router(tags.router, prefix="/api", tags=["tags"])
app.include_router(config.router, prefix="/api", tags=["config"])
app.include_router(model_capabilities.router, tags=["model-capabilities"])
app.include_router(usage_statistics.router, tags=["usage-statistics"])
app.include_router(database.router, prefix="/api/system", tags=["database"])
app.include_router(operation_logs.router, prefix="/api/system", tags=["operation_logs"])
# æ–°å¢ï¼šç³»ç»Ÿé…ç½®åªè¯»æ‘˜è¦
from app.routers import system_config as system_config_router
app.include_router(system_config_router.router, prefix="/api/system", tags=["system"])

# é€šçŸ¥æ¨¡å—ï¼ˆREST + SSEï¼‰
app.include_router(notifications_router.router, prefix="/api", tags=["notifications"])

# å®šæ—¶ä»»åŠ¡ç®¡ç†
app.include_router(scheduler_router.router, tags=["scheduler"])

app.include_router(sse.router, prefix="/api/stream", tags=["streaming"])
app.include_router(sync_router.router)
app.include_router(multi_source_sync.router)
app.include_router(paper_router.router, prefix="/api", tags=["paper"])
app.include_router(tushare_init.router, prefix="/api", tags=["tushare-init"])
app.include_router(akshare_init.router, prefix="/api", tags=["akshare-init"])
app.include_router(baostock_init.router, prefix="/api", tags=["baostock-init"])
app.include_router(historical_data.router, tags=["historical-data"])
app.include_router(multi_period_sync.router, tags=["multi-period-sync"])
app.include_router(financial_data.router, tags=["financial-data"])
app.include_router(news_data.router, tags=["news-data"])
app.include_router(social_media.router, tags=["social-media"])
app.include_router(internal_messages.router, tags=["internal-messages"])


@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›APIä¿¡æ¯"""
    print("ğŸ  æ ¹è·¯å¾„è¢«è®¿é—®")
    return {
        "name": "TradingAgents-CN API",
        "version": "0.1.16",
        "status": "running",
        "docs_url": "/docs" if settings.DEBUG else None
    }


if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.DEBUG,
        log_level="info",
        reload_dirs=["app"] if settings.DEBUG else None,
        reload_excludes=[
            "__pycache__",
            "*.pyc",
            "*.pyo",
            "*.pyd",
            ".git",
            ".pytest_cache",
            "*.log",
            "*.tmp"
        ] if settings.DEBUG else None,
        reload_includes=["*.py"] if settings.DEBUG else None
    )
"""
Multi-source synchronization API routes
Provides endpoints for multi-source stock data synchronization
"""
import asyncio
import logging
from typing import Dict, List, Optional, Any, Union
from fastapi import APIRouter, HTTPException, Query
from pydantic import BaseModel

from app.services.multi_source_basics_sync_service import get_multi_source_sync_service
from app.services.data_sources.manager import DataSourceManager

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/sync/multi-source", tags=["Multi-Source Sync"])


class SyncRequest(BaseModel):
    """åŒæ­¥è¯·æ±‚æ¨¡å‹"""
    force: bool = False
    preferred_sources: Optional[List[str]] = None


class SyncResponse(BaseModel):
    """åŒæ­¥å“åº”æ¨¡å‹"""
    success: bool
    message: str
    data: Union[Dict[str, Any], List[Any], Any]


class DataSourceStatus(BaseModel):
    """æ•°æ®æºçŠ¶æ€æ¨¡å‹"""
    name: str
    priority: int
    available: bool
    description: str


@router.get("/sources/status")
async def get_data_sources_status():
    """è·å–æ‰€æœ‰æ•°æ®æºçš„çŠ¶æ€"""
    try:
        manager = DataSourceManager()
        available_adapters = manager.get_available_adapters()
        all_adapters = manager.adapters

        status_list = []
        for adapter in all_adapters:
            is_available = adapter in available_adapters

            # æ ¹æ®æ•°æ®æºç±»å‹æä¾›æè¿°
            descriptions = {
                "tushare": "ä¸“ä¸šé‡‘èæ•°æ®APIï¼Œæä¾›é«˜è´¨é‡çš„Aè‚¡æ•°æ®å’Œè´¢åŠ¡æŒ‡æ ‡",
                "akshare": "å¼€æºé‡‘èæ•°æ®åº“ï¼Œæä¾›åŸºç¡€çš„è‚¡ç¥¨ä¿¡æ¯",
                "baostock": "å…è´¹å¼€æºçš„è¯åˆ¸æ•°æ®å¹³å°ï¼Œæä¾›å†å²æ•°æ®"
            }

            status_list.append({
                "name": adapter.name,
                "priority": adapter.priority,
                "available": is_available,
                "description": descriptions.get(adapter.name, f"{adapter.name}æ•°æ®æº")
            })

        return SyncResponse(
            success=True,
            message="Data sources status retrieved successfully",
            data=status_list
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get data sources status: {str(e)}")


@router.get("/status")
async def get_sync_status():
    """è·å–å¤šæ•°æ®æºåŒæ­¥çŠ¶æ€"""
    try:
        service = get_multi_source_sync_service()
        status = await service.get_status()
        
        return SyncResponse(
            success=True,
            message="Status retrieved successfully",
            data=status
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get sync status: {str(e)}")


@router.post("/stock_basics/run")
async def run_stock_basics_sync(
    force: bool = Query(False, description="æ˜¯å¦å¼ºåˆ¶è¿è¡ŒåŒæ­¥"),
    preferred_sources: Optional[str] = Query(None, description="ä¼˜å…ˆä½¿ç”¨çš„æ•°æ®æºï¼Œç”¨é€—å·åˆ†éš”")
):
    """è¿è¡Œå¤šæ•°æ®æºè‚¡ç¥¨åŸºç¡€ä¿¡æ¯åŒæ­¥"""
    try:
        service = get_multi_source_sync_service()
        
        # è§£æä¼˜å…ˆæ•°æ®æº
        sources_list = None
        if preferred_sources and isinstance(preferred_sources, str):
            sources_list = [s.strip() for s in preferred_sources.split(",") if s.strip()]
        
        # è¿è¡ŒåŒæ­¥
        result = await service.run_full_sync(force=force, preferred_sources=sources_list)
        
        # åˆ¤æ–­æ˜¯å¦æˆåŠŸ
        success = result.get("status") in ["success", "success_with_errors"]
        message = "Synchronization completed successfully"
        
        if result.get("status") == "success_with_errors":
            message = f"Synchronization completed with {result.get('errors', 0)} errors"
        elif result.get("status") == "failed":
            message = f"Synchronization failed: {result.get('message', 'Unknown error')}"
            success = False
        elif result.get("status") == "running":
            message = "Synchronization is already running"
        
        return SyncResponse(
            success=success,
            message=message,
            data=result
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to run synchronization: {str(e)}")


async def _test_single_adapter(adapter) -> dict:
    """
    åœ¨åå°çº¿ç¨‹ä¸­æµ‹è¯•å•ä¸ªæ•°æ®æºé€‚é…å™¨
    é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
    """
    result = {
        "name": adapter.name,
        "priority": adapter.priority,
        "available": True,
        "tests": {}
    }

    # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨è·å–
    try:
        # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥æ–¹æ³•ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
        df = await asyncio.to_thread(adapter.get_stock_list)
        if df is not None and not df.empty:
            result["tests"]["stock_list"] = {
                "success": True,
                "count": len(df),
                "message": f"Successfully fetched {len(df)} stocks"
            }
        else:
            result["tests"]["stock_list"] = {
                "success": False,
                "count": 0,
                "message": "No stock data returned"
            }
    except Exception as e:
        result["tests"]["stock_list"] = {
            "success": False,
            "count": 0,
            "message": f"Error: {str(e)}"
        }

    # æµ‹è¯•æœ€æ–°äº¤æ˜“æ—¥æœŸæŸ¥æ‰¾
    try:
        trade_date = await asyncio.to_thread(adapter.find_latest_trade_date)
        if trade_date:
            result["tests"]["trade_date"] = {
                "success": True,
                "date": trade_date,
                "message": f"Found latest trade date: {trade_date}"
            }
        else:
            result["tests"]["trade_date"] = {
                "success": False,
                "date": None,
                "message": "No trade date found"
            }
    except Exception as e:
        result["tests"]["trade_date"] = {
            "success": False,
            "date": None,
            "message": f"Error: {str(e)}"
        }

    # æµ‹è¯•æ¯æ—¥åŸºç¡€æ•°æ®è·å–ï¼ˆå¦‚æœæ”¯æŒï¼‰
    try:
        trade_date = result["tests"]["trade_date"].get("date")
        if trade_date:
            df = await asyncio.to_thread(adapter.get_daily_basic, trade_date)
            if df is not None and not df.empty:
                result["tests"]["daily_basic"] = {
                    "success": True,
                    "count": len(df),
                    "message": f"Successfully fetched daily data for {len(df)} stocks"
                }
            else:
                result["tests"]["daily_basic"] = {
                    "success": False,
                    "count": 0,
                    "message": "No daily basic data available or not supported"
                }
        else:
            result["tests"]["daily_basic"] = {
                "success": False,
                "count": 0,
                "message": "Cannot test without valid trade date"
            }
    except Exception as e:
        result["tests"]["daily_basic"] = {
            "success": False,
            "count": 0,
            "message": f"Error: {str(e)}"
        }

    return result


@router.post("/test-sources")
async def test_data_sources():
    """
    æµ‹è¯•æ‰€æœ‰æ•°æ®æºçš„è¿æ¥å’Œæ•°æ®è·å–èƒ½åŠ›

    æ³¨æ„ï¼šæ­¤æ¥å£ä¼šæ‰§è¡Œè€—æ—¶æ“ä½œï¼ˆè·å–è‚¡ç¥¨åˆ—è¡¨ç­‰ï¼‰ï¼Œ
    æ‰€æœ‰åŒæ­¥æ“ä½œéƒ½åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
    """
    try:
        manager = DataSourceManager()
        available_adapters = manager.get_available_adapters()

        logger.info(f"ğŸ§ª å¼€å§‹æµ‹è¯• {len(available_adapters)} ä¸ªæ•°æ®æº...")

        # å¹¶å‘æµ‹è¯•æ‰€æœ‰é€‚é…å™¨ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œï¼‰
        test_tasks = [_test_single_adapter(adapter) for adapter in available_adapters]
        test_results = await asyncio.gather(*test_tasks, return_exceptions=True)

        # å¤„ç†å¼‚å¸¸ç»“æœ
        final_results = []
        for i, result in enumerate(test_results):
            if isinstance(result, Exception):
                logger.error(f"âŒ æµ‹è¯•é€‚é…å™¨ {available_adapters[i].name} æ—¶å‡ºé”™: {result}")
                final_results.append({
                    "name": available_adapters[i].name,
                    "priority": available_adapters[i].priority,
                    "available": False,
                    "tests": {
                        "error": {
                            "success": False,
                            "message": f"Test failed: {str(result)}"
                        }
                    }
                })
            else:
                final_results.append(result)

        logger.info(f"âœ… æ•°æ®æºæµ‹è¯•å®Œæˆï¼Œå…±æµ‹è¯• {len(final_results)} ä¸ªæ•°æ®æº")

        return SyncResponse(
            success=True,
            message=f"Tested {len(final_results)} data sources",
            data={"test_results": final_results}
        )

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ•°æ®æºæ—¶å‡ºé”™: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to test data sources: {str(e)}")


@router.get("/recommendations")
async def get_sync_recommendations():
    """è·å–æ•°æ®æºä½¿ç”¨å»ºè®®"""
    try:
        manager = DataSourceManager()
        available_adapters = manager.get_available_adapters()
        
        recommendations = {
            "primary_source": None,
            "fallback_sources": [],
            "suggestions": [],
            "warnings": []
        }
        
        if available_adapters:
            # æ¨èä¼˜å…ˆçº§æœ€é«˜çš„å¯ç”¨æ•°æ®æºä½œä¸ºä¸»æ•°æ®æº
            primary = available_adapters[0]
            recommendations["primary_source"] = {
                "name": primary.name,
                "priority": primary.priority,
                "reason": "Highest priority available data source"
            }
            
            # å…¶ä»–å¯ç”¨æ•°æ®æºä½œä¸ºå¤‡ç”¨
            for adapter in available_adapters[1:]:
                recommendations["fallback_sources"].append({
                    "name": adapter.name,
                    "priority": adapter.priority
                })
        
        # ç”Ÿæˆå»ºè®®
        if not available_adapters:
            recommendations["warnings"].append("No data sources are available. Please check your configuration.")
        elif len(available_adapters) == 1:
            recommendations["suggestions"].append("Consider configuring additional data sources for redundancy.")
        else:
            recommendations["suggestions"].append(f"You have {len(available_adapters)} data sources available, which provides good redundancy.")
        
        # ç‰¹å®šæ•°æ®æºçš„å»ºè®®
        tushare_available = any(a.name == "tushare" for a in available_adapters)
        if not tushare_available:
            recommendations["suggestions"].append("Consider configuring Tushare for the most comprehensive financial data.")
        
        return SyncResponse(
            success=True,
            message="Recommendations generated successfully",
            data=recommendations
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to generate recommendations: {str(e)}")


@router.get("/history")
async def get_sync_history(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(10, ge=1, le=50, description="æ¯é¡µå¤§å°"),
    status: Optional[str] = Query(None, description="çŠ¶æ€ç­›é€‰")
):
    """è·å–åŒæ­¥å†å²è®°å½•"""
    try:
        from app.core.database import get_mongo_db
        db = get_mongo_db()

        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = {"job": "stock_basics_multi_source"}
        if status:
            query["status"] = status

        # è®¡ç®—è·³è¿‡çš„è®°å½•æ•°
        skip = (page - 1) * page_size

        # æŸ¥è¯¢å†å²è®°å½•
        cursor = db.sync_status.find(query).sort("started_at", -1).skip(skip).limit(page_size)
        history_records = await cursor.to_list(length=page_size)

        # è·å–æ€»æ•°
        total = await db.sync_status.count_documents(query)

        # æ¸…ç†è®°å½•ä¸­çš„ _id å­—æ®µ
        for record in history_records:
            record.pop("_id", None)

        return SyncResponse(
            success=True,
            message="History retrieved successfully",
            data={
                "records": history_records,
                "total": total,
                "page": page,
                "page_size": page_size,
                "has_more": skip + len(history_records) < total
            }
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get sync history: {str(e)}")


@router.delete("/cache")
async def clear_sync_cache():
    """æ¸…ç©ºåŒæ­¥ç›¸å…³çš„ç¼“å­˜"""
    try:
        service = get_multi_source_sync_service()

        # æ¸…ç©ºåŒæ­¥çŠ¶æ€ç¼“å­˜
        cleared_items = 0

        # 1. æ¸…ç©ºåŒæ­¥çŠ¶æ€
        try:
            from app.core.database import get_mongo_db
            db = get_mongo_db()

            # åˆ é™¤åŒæ­¥çŠ¶æ€è®°å½•
            result = await db.sync_status.delete_many({"job": "stock_basics_multi_source"})
            cleared_items += result.deleted_count

            # é‡ç½®æœåŠ¡çŠ¶æ€
            service._running = False

        except Exception as e:
            logger.warning(f"Failed to clear sync status cache: {e}")

        # 2. æ¸…ç©ºæ•°æ®æºç¼“å­˜ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        try:
            manager = DataSourceManager()
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ•°æ®æºç‰¹å®šçš„ç¼“å­˜æ¸…ç†é€»è¾‘
            # ç›®å‰æ•°æ®æºé€‚é…å™¨æ²¡æœ‰æŒä¹…åŒ–ç¼“å­˜ï¼Œæ‰€ä»¥è·³è¿‡
        except Exception as e:
            logger.warning(f"Failed to clear data source cache: {e}")

        return SyncResponse(
            success=True,
            message=f"Cache cleared successfully, {cleared_items} items removed",
            data={"cleared": True, "items_cleared": cleared_items}
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to clear cache: {str(e)}")

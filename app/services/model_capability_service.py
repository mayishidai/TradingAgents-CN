"""
æ¨¡å‹èƒ½åŠ›ç®¡ç†æœåŠ¡

æä¾›æ¨¡å‹èƒ½åŠ›è¯„ä¼°ã€éªŒè¯å’Œæ¨èåŠŸèƒ½ã€‚
"""

from typing import Tuple, Dict, Optional, List, Any
from app.constants.model_capabilities import (
    ANALYSIS_DEPTH_REQUIREMENTS,
    DEFAULT_MODEL_CAPABILITIES,
    CAPABILITY_DESCRIPTIONS,
    ModelRole,
    ModelFeature
)
from app.core.unified_config import unified_config
import logging

logger = logging.getLogger(__name__)


class ModelCapabilityService:
    """æ¨¡å‹èƒ½åŠ›ç®¡ç†æœåŠ¡"""
    
    def get_model_capability(self, model_name: str) -> int:
        """
        è·å–æ¨¡å‹çš„èƒ½åŠ›ç­‰çº§
        
        Args:
            model_name: æ¨¡å‹åç§°
            
        Returns:
            èƒ½åŠ›ç­‰çº§ (1-5)
        """
        # 1. ä¼˜å…ˆä»æ•°æ®åº“é…ç½®è¯»å–
        try:
            llm_configs = unified_config.get_llm_configs()
            for config in llm_configs:
                if config.model_name == model_name:
                    return getattr(config, 'capability_level', 2)
        except Exception as e:
            logger.warning(f"ä»é…ç½®è¯»å–æ¨¡å‹èƒ½åŠ›å¤±è´¥: {e}")
        
        # 2. ä»é»˜è®¤æ˜ å°„è¡¨è¯»å–
        if model_name in DEFAULT_MODEL_CAPABILITIES:
            return DEFAULT_MODEL_CAPABILITIES[model_name]["capability_level"]
        
        # 3. é»˜è®¤è¿”å›æ ‡å‡†ç­‰çº§
        logger.warning(f"æœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„èƒ½åŠ›ç­‰çº§ï¼Œä½¿ç”¨é»˜è®¤å€¼2")
        return 2
    
    def get_model_config(self, model_name: str) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹çš„å®Œæ•´é…ç½®ä¿¡æ¯
        
        Args:
            model_name: æ¨¡å‹åç§°
            
        Returns:
            æ¨¡å‹é…ç½®å­—å…¸
        """
        # 1. ä¼˜å…ˆä»æ•°æ®åº“é…ç½®è¯»å–
        try:
            llm_configs = unified_config.get_llm_configs()
            for config in llm_configs:
                if config.model_name == model_name:
                    return {
                        "model_name": config.model_name,
                        "capability_level": getattr(config, 'capability_level', 2),
                        "suitable_roles": getattr(config, 'suitable_roles', [ModelRole.BOTH]),
                        "features": getattr(config, 'features', []),
                        "recommended_depths": getattr(config, 'recommended_depths', ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†"]),
                        "performance_metrics": getattr(config, 'performance_metrics', None)
                    }
        except Exception as e:
            logger.warning(f"ä»é…ç½®è¯»å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}")
        
        # 2. ä»é»˜è®¤æ˜ å°„è¡¨è¯»å–
        if model_name in DEFAULT_MODEL_CAPABILITIES:
            return DEFAULT_MODEL_CAPABILITIES[model_name]
        
        # 3. è¿”å›é»˜è®¤é…ç½®
        logger.warning(f"æœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return {
            "model_name": model_name,
            "capability_level": 2,
            "suitable_roles": [ModelRole.BOTH],
            "features": [ModelFeature.TOOL_CALLING],
            "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†"],
            "performance_metrics": {"speed": 3, "cost": 3, "quality": 3}
        }
    
    def validate_model_pair(
        self,
        quick_model: str,
        deep_model: str,
        research_depth: str
    ) -> Dict[str, Any]:
        """
        éªŒè¯æ¨¡å‹å¯¹æ˜¯å¦é€‚åˆå½“å‰åˆ†ææ·±åº¦
        
        Args:
            quick_model: å¿«é€Ÿåˆ†ææ¨¡å‹åç§°
            deep_model: æ·±åº¦åˆ†ææ¨¡å‹åç§°
            research_depth: ç ”ç©¶æ·±åº¦ï¼ˆå¿«é€Ÿ/åŸºç¡€/æ ‡å‡†/æ·±åº¦/å…¨é¢ï¼‰
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸ï¼ŒåŒ…å« valid, warnings, recommendations
        """
        requirements = ANALYSIS_DEPTH_REQUIREMENTS.get(research_depth, ANALYSIS_DEPTH_REQUIREMENTS["æ ‡å‡†"])
        
        quick_config = self.get_model_config(quick_model)
        deep_config = self.get_model_config(deep_model)
        
        result = {
            "valid": True,
            "warnings": [],
            "recommendations": []
        }
        
        # æ£€æŸ¥å¿«é€Ÿæ¨¡å‹
        quick_level = quick_config["capability_level"]
        if quick_level < requirements["quick_model_min"]:
            result["warnings"].append(
                f"âš ï¸ å¿«é€Ÿæ¨¡å‹ {quick_model} (èƒ½åŠ›ç­‰çº§{quick_level}) "
                f"ä½äº {research_depth} åˆ†æçš„å»ºè®®ç­‰çº§({requirements['quick_model_min']})"
            )
        
        # æ£€æŸ¥å¿«é€Ÿæ¨¡å‹è§’è‰²é€‚é…
        quick_roles = quick_config.get("suitable_roles", [])
        if ModelRole.QUICK_ANALYSIS not in quick_roles and ModelRole.BOTH not in quick_roles:
            result["warnings"].append(
                f"ğŸ’¡ æ¨¡å‹ {quick_model} ä¸æ˜¯ä¸ºå¿«é€Ÿåˆ†æä¼˜åŒ–çš„ï¼Œå¯èƒ½å½±å“æ•°æ®æ”¶é›†æ•ˆç‡"
            )
        
        # æ£€æŸ¥å¿«é€Ÿæ¨¡å‹æ˜¯å¦æ”¯æŒå·¥å…·è°ƒç”¨
        quick_features = quick_config.get("features", [])
        if ModelFeature.TOOL_CALLING not in quick_features:
            result["valid"] = False
            result["warnings"].append(
                f"âŒ å¿«é€Ÿæ¨¡å‹ {quick_model} ä¸æ”¯æŒå·¥å…·è°ƒç”¨ï¼Œæ— æ³•å®Œæˆæ•°æ®æ”¶é›†ä»»åŠ¡"
            )
        
        # æ£€æŸ¥æ·±åº¦æ¨¡å‹
        deep_level = deep_config["capability_level"]
        if deep_level < requirements["deep_model_min"]:
            result["valid"] = False
            result["warnings"].append(
                f"âŒ æ·±åº¦æ¨¡å‹ {deep_model} (èƒ½åŠ›ç­‰çº§{deep_level}) "
                f"ä¸æ»¡è¶³ {research_depth} åˆ†æçš„æœ€ä½è¦æ±‚(ç­‰çº§{requirements['deep_model_min']})"
            )
            result["recommendations"].append(
                self._recommend_model("deep", requirements["deep_model_min"])
            )
        
        # æ£€æŸ¥æ·±åº¦æ¨¡å‹è§’è‰²é€‚é…
        deep_roles = deep_config.get("suitable_roles", [])
        if ModelRole.DEEP_ANALYSIS not in deep_roles and ModelRole.BOTH not in deep_roles:
            result["warnings"].append(
                f"ğŸ’¡ æ¨¡å‹ {deep_model} ä¸æ˜¯ä¸ºæ·±åº¦æ¨ç†ä¼˜åŒ–çš„ï¼Œå¯èƒ½å½±å“åˆ†æè´¨é‡"
            )
        
        # æ£€æŸ¥å¿…éœ€ç‰¹æ€§
        for feature in requirements["required_features"]:
            if feature == ModelFeature.REASONING:
                deep_features = deep_config.get("features", [])
                if feature not in deep_features:
                    result["warnings"].append(
                        f"ğŸ’¡ {research_depth} åˆ†æå»ºè®®ä½¿ç”¨å…·æœ‰å¼ºæ¨ç†èƒ½åŠ›çš„æ·±åº¦æ¨¡å‹"
                    )
        
        return result
    
    def recommend_models_for_depth(
        self,
        research_depth: str
    ) -> Tuple[str, str]:
        """
        æ ¹æ®åˆ†ææ·±åº¦æ¨èåˆé€‚çš„æ¨¡å‹å¯¹
        
        Args:
            research_depth: ç ”ç©¶æ·±åº¦ï¼ˆå¿«é€Ÿ/åŸºç¡€/æ ‡å‡†/æ·±åº¦/å…¨é¢ï¼‰
            
        Returns:
            (quick_model, deep_model) å…ƒç»„
        """
        requirements = ANALYSIS_DEPTH_REQUIREMENTS.get(research_depth, ANALYSIS_DEPTH_REQUIREMENTS["æ ‡å‡†"])
        
        # è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹
        try:
            llm_configs = unified_config.get_llm_configs()
            enabled_models = [c for c in llm_configs if c.enabled]
        except Exception as e:
            logger.error(f"è·å–æ¨¡å‹é…ç½®å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤æ¨¡å‹
            return self._get_default_models()
        
        if not enabled_models:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self._get_default_models()
        
        # ç­›é€‰é€‚åˆå¿«é€Ÿåˆ†æçš„æ¨¡å‹
        quick_candidates = []
        for m in enabled_models:
            roles = getattr(m, 'suitable_roles', [ModelRole.BOTH])
            level = getattr(m, 'capability_level', 2)
            features = getattr(m, 'features', [])
            
            if (ModelRole.QUICK_ANALYSIS in roles or ModelRole.BOTH in roles) and \
               level >= requirements["quick_model_min"] and \
               ModelFeature.TOOL_CALLING in features:
                quick_candidates.append(m)
        
        # ç­›é€‰é€‚åˆæ·±åº¦åˆ†æçš„æ¨¡å‹
        deep_candidates = []
        for m in enabled_models:
            roles = getattr(m, 'suitable_roles', [ModelRole.BOTH])
            level = getattr(m, 'capability_level', 2)
            
            if (ModelRole.DEEP_ANALYSIS in roles or ModelRole.BOTH in roles) and \
               level >= requirements["deep_model_min"]:
                deep_candidates.append(m)
        
        # æŒ‰æ€§ä»·æ¯”æ’åºï¼ˆèƒ½åŠ›ç­‰çº§ vs æˆæœ¬ï¼‰
        quick_candidates.sort(
            key=lambda x: (
                getattr(x, 'capability_level', 2),
                -getattr(x, 'performance_metrics', {}).get("cost", 3) if getattr(x, 'performance_metrics', None) else 0
            ),
            reverse=True
        )
        
        deep_candidates.sort(
            key=lambda x: (
                getattr(x, 'capability_level', 2),
                getattr(x, 'performance_metrics', {}).get("quality", 3) if getattr(x, 'performance_metrics', None) else 0
            ),
            reverse=True
        )
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        quick_model = quick_candidates[0].model_name if quick_candidates else None
        deep_model = deep_candidates[0].model_name if deep_candidates else None
        
        # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚çš„ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤
        if not quick_model or not deep_model:
            return self._get_default_models()
        
        logger.info(
            f"ğŸ¤– ä¸º {research_depth} åˆ†ææ¨èæ¨¡å‹: "
            f"quick={quick_model} (è§’è‰²:å¿«é€Ÿåˆ†æ), "
            f"deep={deep_model} (è§’è‰²:æ·±åº¦æ¨ç†)"
        )
        
        return quick_model, deep_model
    
    def _get_default_models(self) -> Tuple[str, str]:
        """è·å–é»˜è®¤æ¨¡å‹å¯¹"""
        try:
            quick_model = unified_config.get_quick_analysis_model()
            deep_model = unified_config.get_deep_analysis_model()
            logger.info(f"ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ¨¡å‹: quick={quick_model}, deep={deep_model}")
            return quick_model, deep_model
        except Exception as e:
            logger.error(f"è·å–é»˜è®¤æ¨¡å‹å¤±è´¥: {e}")
            return "qwen-turbo", "qwen-plus"
    
    def _recommend_model(self, model_type: str, min_level: int) -> str:
        """æ¨èæ»¡è¶³è¦æ±‚çš„æ¨¡å‹"""
        try:
            llm_configs = unified_config.get_llm_configs()
            for config in llm_configs:
                if config.enabled and getattr(config, 'capability_level', 2) >= min_level:
                    display_name = config.model_display_name or config.model_name
                    return f"å»ºè®®ä½¿ç”¨: {display_name}"
        except Exception as e:
            logger.warning(f"æ¨èæ¨¡å‹å¤±è´¥: {e}")
        
        return "å»ºè®®å‡çº§æ¨¡å‹é…ç½®"


# å•ä¾‹
_model_capability_service = None


def get_model_capability_service() -> ModelCapabilityService:
    """è·å–æ¨¡å‹èƒ½åŠ›æœåŠ¡å•ä¾‹"""
    global _model_capability_service
    if _model_capability_service is None:
        _model_capability_service = ModelCapabilityService()
    return _model_capability_service

